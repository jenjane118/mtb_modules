---
title: "Mycobacterium gene module clustering"
output: html_notebook
---

******
# Reading and Resources

1. Yen Yi's MRes report [Large Scale Computational Analysis of Coding and Non-coding Element Expression in Mycobacterium tuberculosis](Mycobacteria_project/HBXV7_AMS_MSCI_DISSERTATION_SUBMISSION.pdf)

2. Rosanna's MRes report [Computational analysis of combined RNA-seq datasets to predict novel ncRNAs in Mycobacterium tuberculosis](Mycobacteria_project/MRes_dissertation_RJ.pdf)

3. Baerhunter paper [Ozuna, A., Liberto, D., Joyce, R. M., Arnvig, K. B., & Nobeli, I. (2019). baerhunter: an R package for the discovery and analysis of expressed non-coding regions in bacterial RNA-seq data. Bioinformatics.] (https://doi.org/10.1093/bioinformatics/btz643)
[supplementary data](https://academic.oup.com/bioinformatics/article-abstract/36/3/966/5550627?redirectedFrom=fulltext)



## work on gathering/annotating list of ncRNAs in mtb

***literature search***

Papers that identify ncRNA in mtb

1. [Cortes T, Schubert OT, Rose G, Arnvig KB, Comas I, Aebersold R, Young DB. 2013. Genome-wide mapping of transcriptional start sites defines an extensive leaderless transcriptome in Mycobacterium tuberculosis. Cell Rep. 5:1121–1131. ](http://dx.doi.org/10.1016/ j.celrep.2013.10.031)

    -TSS validation

2. [Arnvig KB, Comas I, Thomson NR, Houghton J, Boshoff HI, Croucher NJ, Rose G, Perkins TT, Parkhill J, Dougan G, Young DB. 2011. Sequence-based analysis uncovers an abundance of non-coding RNA in the total transcriptome of Mycobacterium tuberculosis. PLoS Pathog. 7:e1002342. ](http://dx.doi.org/10.1371/journal.ppat.1002342)

3. [Miotto P, Forti F, Ambrosi A, Pellin D, Veiga DF, Balazsi G, Gennaro ML, Di Serio C, Ghisotti D, Cirillo DM. 2012. Genome-wide discovery of small RNAs in Mycobacterium tuberculosis. PLoS One 7:e51950. ](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0051950) 

4. [Dejesus, M. A. et al. Comprehensive essentiality analysis of the Mycobacterium tuberculosis genome via saturating transposon mutagenesis. MBio 8, 1–17 (2017).](https://mbio.asm.org/content/8/1/e02133-16)

  -esp S5(UTRs and promoters), S4 (predicted sRNAs), uses 'BS_finder'
  
5. [Shell SS, Wang J, Lapierre P, Mir M, Chase MR, Pyle MM, Gawande R, Ahmad R, Sarracino DA, Ioerger TR, Fortune SM, Derbyshire KM, Wade JT, Gray TA. 2015. Leaderless transcripts and small proteins are common features of the mycobacterial translational landscape. PLoS Genet11:e1005641. doi:10.1371/journal.pgen.1005641](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1005641)

-TSS validation

6. [Arnvig KB, Young DB. 2009. Identification of small RNAs in Mycobacte- rium tuberculosis. Mol Microbiol 73:397–408. ](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-2958.2009.06777.x)

7. [DiChiara JM, Contreras-Martinez LM, Livny J, Smith D, McDonough KA, Belfort M. 2010. Multiple small RNAs identified in Mycobacterium bovis BCG are also expressed in Mycobacterium tuberculosis and Mycobacterium smegmatis. ](https://academic.oup.com/nar/article/38/12/4067/2409235)

8. [Wang M, Fleming J, Li Z, Li C, Zhang H, Xue Y, Chen M, Zhang Z, Zhang XE, Bi L. 2016. An automated approach for global identification of sRNA-encoding regions in RNA-Seq data from Mycobacterium tuberculosis. Acta Biochim Biophys Sin (Shanghai) 48:544–553. ](https://academic.oup.com/abbs/article/48/6/544/2195062)

9. [Mycobrowser website lists 62 putative ncRNA genes](https://mycobrowser.epfl.ch/home/about)

  can't download the list! use only for looking up particular ncRNAs

10. [Rfam database lists 22 sRNAs, 12 with structure](https://rfam.xfam.org/search?q=mycobacterium%20tuberculosis%20AND%20rna_type:%22sRNA%22%20AND%20TAXONOMY:%2283332%22)


11. [Gerrick, E. R. et al. Small RNA profiling in mycobacterium tuberculosis identifies mrsi as necessary for an anticipatory iron sparing response. Proc. Natl. Acad. Sci. U. S. A. 115, 6464–6469 (2018). ](https://www.pnas.org/content/115/25/6464)

  saved S1 list of putative predicted sRNAs 
  
12. [Dinan, A. M. et al. Relaxed Selection Drives a Noisy Noncoding Transcriptome in Members of the. 5, 1–9 (2014). ](https://mbio.asm.org/content/5/4/e01169-14)

13. [Gómez-Lozano, M., Marvig, R., Molin, S., & Long, K. (2014). Identification of Bacterial Small RNAs by RNA Sequencing. In Methods in molecular biology. ](https://doi.org/10.1007/978-1-4939-0473-0_34)

  Molecular biology protocol to enrich for sRNAs in RNAseq experiments using size-selected libraries. Includes bioinformatics analysis of RNAseq data, and the description of an algorithm to detect putative sRNAs in the coverage data. Transcripts that start and end in intergenic regions, suddenly increasing beyond a read-depth threshold. A second criteria of an ‘average transcriptional level’ (the normalized read coverage depth/length of transcript) must be twice the read-depth threshold cutoff.


Should I start with Gerrick et al and Tine's published list (Cortes), UTR's from Shell, et al and then use essentiality info from DeJesus? look at baerhunter predictions and Tine's unpublished list

Definitely: name (using 'new' system with ncRv1 as prefix), any old name that is used in literature, start, stop, strand, references, 'verified by' (for example RACE, northern blot, etc), 5' TSS


other info: expression conditions measured, flanking genes (though this is basically included in name and position above), RFAM, log2fold change in different conditions

start with first set. Should I have list of references and legend, or use PMID? might be easier for our use if have references listed.

Naming protocol using:

[Lamichhane, G., Arnvig, K. B. & McDonough, K. A. Definition and annotation of (myco)bacterial non-coding RNA. Tuberculosis 93, 26–29 (2013).](https://doi.org/10.1016/j.tube.2012.11.010)

Will focus on Arnvig list of ncRNAs. Cross-check Gerrick's (and DeJesus's?) computationally predicted ncRNAs with validated TSS sites from Shell and Cortes papers.

use union of TSSs in both conditions in Cortes paper

need to find TSS that lies in 10 nt before/within gene boundary and include actual TSS coordinate in df for Gerrick annotations

file is:  Gerrick_ncRNA_TSS_positions.txt


perhaps create an overlap index (Jaccard index) to figure out how much the genomic ranges overlap between sets 

[The BSGatlas: An enhanced annotation of genes and transcripts for the Bacillus subtilis genome with improved information access ](https://www.biorxiv.org/content/10.1101/807263v1.full)


also, Irilenia gave me file of highly expressed ncRNAs from Rosanna's mRes: "/Mycobacteria_project/combined_h37rv_Mtb_high_expressed.gff3""

but decided to run baerhunter again using Yen-yi's .bam files:
/d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/

accessions_M.txt   PRJNA278760_22_Safa  QC_original         test_bam
Local_scripts      PRJNA327080_15       QC_postBWAmem
PRJEB19976_15p_SE  PRJNA390669_12       QC_postfastp
PRJEB65014_3       PRJNA507615_12_SE    QC_posttrimmomatic


install baerhunter on thoth R library

```{bash}
module load R/v4.0.1
```

```{R}
install.packages("devtools")
#Warning in install.packages("devtools") :
#  'lib = "/s/software/R/v4.0.1/lib64/R/library"' is not writable
#Would you like to use a personal library instead? (yes/No/cancel) yes
#Would you like to create a personal library
#‘~/R/x86_64-pc-linux-gnu-library/4.0’
#to install packages into? (yes/No/cancel) No
#Error in install.packages("devtools") : unable to install packages


install.packages("devtools")
#Warning in install.packages("devtools") :
#  'lib = "/s/software/R/v4.0.1/lib64/R/library"' is not writable
#Would you like to use a personal library instead? (yes/No/cancel) yes
#Would you like to create a personal library
#‘~/R/x86_64-pc-linux-gnu-library/4.0’
#to install packages into? (yes/No/cancel) yes

```

should I rename this library?

also installed baerhunter and all dependencies (see baerhunter_trial.R)

```{R}
library(baerhunter)
library(GenomicAlignments)
library(IRanges)
library(Rsamtools)
library(Rsubread)
library(DESeq2)

feature_file_editor(bam_directory="/d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA278760_22_Safa",
                    original_annotation_file="MtbH37RvNC_000962.3.gff",
                    annot_file_dir = "/d/in16/u/sj003/refseqs/Mtb/",
                    output_file="/d/projects/u/sj003/output_BH_12_10/PRJNA278760_22.gff3",
                    original_sRNA_annotation="ncRNA",
                    low_coverage_cutoff=5, #cutoff for noise
                    high_coverage_cutoff=10,
                    min_sRNA_length=40,
                    min_UTR_length=50,
                    paired_end_data=TRUE,
                    strandedness="stranded")

```

make R script calling above and call in bash:

```{bash}
nohup R CMD BATCH $my_path/scripts/BH_make_gff.R &
```

this is not really working. says 'nohup ignoring input'
tried again without nohup--taking forever

not working no matter what i do, same error:

[1] "Extracted plus strand data from BAM files"
Error in h(simpleError(msg, call)) : 
  error in evaluating the argument 'i' in selecting a method for function '[': 'match' requires vector arguments
Calls: feature_file_editor -> sRNA_calc -> [ -> %in% -> .handleSimpleError -> h
Execution halted


I'm thinking maybe it doesn't work with R version (4.0.1). I'm using R version 3.5.1 (2018-07-02) on my machine. Try loading with that version (3.5.2 on thoth) and try again.

```{bash}
module load R/v3.5.2
```

re-load devtools--makes new personal R library for 3.5

/d/user6/sj003/R/x86_64-pc-linux-gnu-library/3.5

```{R eval=FALSE, include=FALSE}
install.packages("devtools")
library(devtools)
library(IRanges)
library(Rsamtools)
library(DESeq2)
library(Rsubread)
devtools::install_github("irilenia/baerhunter")
library(baerhunter)
```

i don't think the libraries are necessary except for the session used--have to re-load them before using baerhunter, but packages are in personal R library, or general library that R has access to

```{bash}
nohup R CMD BATCH $my_path/scripts/BH_make_gff.R >& BH_make_gff.Rout &
```

got a warning from server that I was exceeding my allocated disk space limits. killed process.

```{bash}
kill%2  ##this is job number
```

looks like it is related to using personal R library in the home directory. need to move this to /d/in16/u/sj003. Deleted 3.5 and 4.0 libraries in home directory.

make files in working directory:
```{bash}
touch .Renviron
touch R_packages
```

.Renviron contains line:  R_LIBS = /d/in16/u/sj003/R_packages

when I reload R and install devtools, this time it works using correct folder.

Irilenia pointed out that "strandedness" refers to +/- stranded datasets. need to confirm this for each library. all of Yen-yi's datasets were reversely stranded.

going to re-do using R in correct directory, and using smallest dataset, PRJEB65014. this corresponds to E-MTAB-6011 (using number of samples, can't look at fastq files to find this identifier). Looked up on sra, this is correct bio-project number.

| bio-project | dataset |
|-----------|------------|
| PRJEB65014 | E-MTAB-6011 |
| PRJNA278760 | GSE670035 |
| PRJNA327080 | GSE83814 |
| PRJNA390669 | GSE100097 |


folder for .bam files:
/d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/

```{R}
library(baerhunter)
library(GenomicAlignments)
library(IRanges)
library(Rsamtools)
library(DESeq2)
library(Rsubread)

# create a directory to hold the output files..
if (!(dir.exists("./output_BH_13_10/"))) { dir.create("./output_BH_13_10/")
}
feature_file_editor(bam_directory="/d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJEB65014_3/BWA_mem/",
                    original_annotation_file="MtbH37RvNC_000962.3.gff",
                    annot_file_dir = "/d/in16/u/sj003/refseqs/Mtb/",
                    output_file="output_BH_13_10/PRJE65014_3.gff3",
                    original_sRNA_annotation="ncRNA",
                    low_coverage_cutoff=5, #cutoff for noise
                    high_coverage_cutoff=10,
                    min_sRNA_length=40,
                    min_UTR_length=50,
                    paired_end_data=TRUE,
                    strandedness="reversely_stranded")

## run with other datasets:
#/d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA278760_22_Safa/
# Done 13/10/20
# /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA327080_15/BWA_mem/
# Done 13/10/20
# /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/

```

OK, that worked! have to use step to create new directory and only include name of directory in working directory, not entire path. Viewed gff3 on artemis. Got gff3 files for all four datasets.

Irilenia is concerned that BH results from PRJNA390669 is very low. check data for strandedness and quality. Strandedness is defo reversely stranded:

![paired end reads showing both strands](Images/prjna_39066912.27.52.png)
![R1 hidden so you can see whether reads correspond to reverse-strand CDS](Images/prjna_390669_12.29.16.png)

It appears that the sRNAs are being called UTRs because the read depth is very high and signal never goes back to zero (noisy). We need to adjust the low/high coverage parameters to eliminate this problem.

From Irilenia: "use bedtools(?) to calculate coverage per position. Then you have the distribution of the coverages and can find the various percentiles of this"

![from suppl info from baerhunter paper](Images/suppl_baerhunter.png)

```{bash}
module load bedtools
bedtools genomecov
```

Tool:    bedtools genomecov (aka genomeCoverageBed)
Version: v2.27.1
Summary: Compute the coverage of a feature file among a genome.

Usage: bedtools genomecov [OPTIONS] -i <bed/gff/vcf> -g <genome>

Options: 
	-ibam		The input file is in BAM format.
			Note: BAM _must_ be sorted by position

From: [bedtools genomecov](https://bedtools.readthedocs.io/en/latest/content/tools/genomecov.html#max-controlling-the-histogram-s-maximum-depth)

-d Reporting “per-base” genome coverage
Using the -d option, bedtools genomecov will compute the depth of feature coverage for each base on each chromosome in genome file provided.

The “per-base” output format is as follows:

chromosome
chromosome position
depth (number) of features overlapping this chromosome position.

-max Controlling the histogram’s maximum depth
Using the -max option, bedtools genomecov will “lump” all positions in the genome having feature coverage greater than or equal to -max into the -max histogram bin. For example, if one sets -max equal to 50, the max depth reported in the output will be 50 and all positions with a depth >= 50 will be represented in bin 50.



```{bash}
bedtools genomecov -ibam /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -d > SRR5689224_cov
```

don't need genome files with .bam files

-bg Reporting genome coverage in BEDGRAPH format.
Whereas the -d option reports an output line describing the observed coverage at each and every position in the genome, the -bg option instead produces genome-wide coverage output in BEDGRAPH format. This is a much more concise representation since consecutive positions with the same coverage are reported as a single output line describing the start and end coordinate of the interval having the coverage level, followed by the coverage level itself.

```{bash}
bedtools genomecov -ibam /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -bg > SRR5689224_coverage.bg
```

this is useless, still finding each base. use -d above.

Now need to plot this in R. should I do this for each .bam and then combine or take mean of each position?

maybe run for each (write script) and then find mean of coverage at each bp?

```{bash}

# script to run bedtools on each .bam file in folder and generate coverage graph for each sample

# module load bedtools
# usage nohup bash /d/in16/u/sj003/scripts/iterate_bedcov.sh >& run_bedcov_out &

#ls /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA327080_15/BWA_mem/*.bam > names.txt

#!/bin/bash

for file in `cat names.txt`

do
        FILENAME=`basename ${file%%.*}`

        echo “File on the loop:                 ${FILENAME}”

# generate coverage plot
        bedtools genomecov -ibam $file -d > ${FILENAME}_cov

        echo -e “#######################\n\n”

done


```


looks like files are a bit uneven in terms of read coverage, for example 24 and 25  and 28 x10 higher than next two samples. make percentage distr bargraph (like one from baerhunter suppl materials above) for each sample.

percentile boxplots for this sample (script in "coverage_plot.R"):
## work with bedgraph coverage files
## make plot with each sample from PRJNA390669_12 to attempt to show lower percentiles fall within a small range (but they don't really seem to in this dataset). 
# use quantiles

see: coverage_plot.R

```{R}
#produces sample quantiles corresponding to the given probabilities. 
# quantile returns estimates of underlying distribution quantiles based on one or two order statistics from
# the supplied elements in x at probabilities in probs.
lapply(cov_df[,3:14], quantile, probs=c(0.05, 0.1, 0.15, 0.20, 0.25, 0.50, 0.75, 1.0))
lapply(cov_df[,3:14], quantile, probs=c(0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.20))
```

![coverage percentiles](Images/PRJNA390669_boxplot.png)

Might want to compare boxplots for individual samples and see if there is any correlation with different conditions?


Do this again with dataset PRJNA327080 (GSE83814) (Safa's dataset with 15 samples)
to see if it is better distributed?

![percentile distribution for PRJNA327080](Images/PRJNA327080_covg_plot.png)



for later when we are comparing datasets, this maybe useful:
[Jaccard statistics using bedtools](http://quinlanlab.org/tutorials/bedtools/bedtools.html)


But perhaps I want to generate a coverage density plot that differentiates between coverage on each strand? 

https://davetang.org/muse/2015/08/05/creating-a-coverage-plot-using-bedtools-and-r/


```{bash}
bedtools genomecov -ibam NA18152.bam -bg -strand +
```

IN suggests seeing what coverage stats look like for cds only.


also, can possibly take into consideration paired end reads?? -pc trackoption
-pc	
Calculates coverage of intervals from left point of a pair reads to the right point.
Works for BAM files only

```{bash}
bedtools genomecov -ibam /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -d -pc -strand + > SRR5689224_pos_cov

bedtools genomecov -ibam /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -d -pc -strand - > SRR5689224_neg_cov
```

run for entire set (changed iterate_bedcov.sh script) and look at boxplots

![positive strand coverage for PRJNA390669_12](Images/PRJNA390669_pos_cov.png)

![negative strand coverage for PRJNA390669_12](Images/prjna390669_neg_cov.png)

need to check results because there should be MORE reads on positive strand, as there are more genes (is this right?). check selected regions on artemis with some of the bams. (which regions? those that should have a lot of positive reads?)

looking at particular region on ARtemis to see why there is such a discrepancy between positive and negative read counts when I used bedtools. put .bam on artemis. compared with read counts file

```
#BAM: /Users/jenniferstiens/git/mtb_modules/SRR5689224_sorted.bam
SRR5689224_sorted.bam	

      	  Sense Antisense  Total	
Rv0002	   2806    2787    5593	
```

This shows that coverage should have been about equal for this feature.

![artemis view of bam read for above sample](Images/ARtemis_screenshot_srr5689224.png)


![bedtools results](Images/bedtools_cov_SRR5689224.png)

so is the program working properly on the positive strand?

Has bedtools switched the positive and negative reads? But the .bam shows reads on both strands. Why are there so many reads on reverse strand in this region?

I think can either do coverage per strand or total for paired end with bedtools genomcov. 

just look at strand specific coverage. otherwise, can we split up into two sets and run paired end on each?

i think i can use samtools to split into strands?

picard tool for finding correct samtools flags:
https://broadinstitute.github.io/picard/explain-flags.html

```{bash}
## to find positive strand aligned reads
## -G excludes only files that match all bits in the flag, 17 indicates reverse strand for paired end reads, so this should include paired end reads on positive strand
samtools view -u /d/in19/u/zchayyt/sample_accessions/PRJNA390669_12_RC/BWA_mem/SRR5689224_sorted.bam -G 17 | samtools depth -a - > SRR5689224_pos.coverage

## to find negative strand aligned reads
## -f outputs files that do match flag, 17 matches reverse strand reads
samtools view -u /d/in19/u/zchayyt/sample_accessions/PRJNA390669_12_RC/BWA_mem/SRR5689224_sorted.bam -f 17 | samtools depth -a - > SRR5689224_neg.coverage

```

counts for the above commands equal the total of unpaired reads

pos: 28494765 + neg:28395408  

```{bash}
 samtools view -c SRR5689235_sorted.bam -f 1
##56890173
```

directory for .bams: /d/in19/u/zchayyt/sample_accessions/PRJNA390669_12_RC/BWA_mem/

write bash script to iterate through bam files in folder and generate coverage files

```{bash iterate_samtools_depth.sh}

# script to use samtools to sort reads from each .bam file in folder by strand and generate coverage file for each sample using samtools depth

# module load samtools
# usage: nohup bash /d/in16/u/sj003/scripts/iterate_samtools_depth.sh >& run_samtools_depth_out &
#ls /d/in19/u/zchayyt/sample_accessions/PRJNA390669_12_RC/BWA_mem/*.bam > names.txt


#!/bin/bash

for file in `cat names.txt`

do
	FILENAME=`basename ${file%%.*}`

	echo “File on the loop:			${FILENAME}”

# filter reads for positive strand and find depth of coverage for each position
  samtools view -u $file -G 17 | samtools depth -a - > ${FILENAME}_pos.coverage


# filter reads for negative strand and find depth of coverage for each position
	samtools view -u $file -f 17 | samtools depth -a - > ${FILENAME}_neg.coverage

	echo -e “#######################\n\n”

done

```

samtools depth: -a returns depth at every position (even zero)

much more reasonable between both. import into R and make barplots.

![Positive strand coverage for sample PRJNA390669_12](Images/PRJNA390669_pos_cov_lo.png)


see samtools_cvg.R

#########################################################################

to find coverage of only coding regions use bedtools coverage:
[bedtools coverage](https://bedtools.readthedocs.io/en/latest/content/tools/coverage.html)

```{bash}
bedtools coverage -b /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -a /d/in16/u/sj003/refseqs/Mtb/MtbH37RvNC_000962.3.gff > SRR5689224_cds_cov.bg
```

-b is .bam and -a is .gff. YES.
-d	Report the depth at each position in each A feature. Positions reported are one based. Each position and depth follow the complete A feature. (don't use--wrong info)
-s	Force “strandedness”. That is, only report hits in B that overlap A on the same strand. By default, overlaps are reported without respect to strand.
-S	Require different strandedness. That is, only report hits in B that overlap A on the _opposite_ strand. By default, overlaps are reported without respect to strand.

results: The number of features in B that overlapped (by at least one base pair) the A interval.

do without strandedness to compare cds?

iterate_bedcov_cds.sh

all zero! 

```{bash}
nohup bedtools coverage -a d/in16/u/sj003/refseqs/Mtb/MtbH37RvNC_000962.3.gff -b /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/*_sorted.bam > bedcov_out.bg >& run_cds_cov_out &
```

try with all bam files in folder rather than iterating through files? will give one number of reads per feature--not related to sequencing depth per sample. not sure this is helpful to us.

Error: Unable to open file d/in16/u/sj003/refseqs/Mtb/MtbH37RvNC_000962.3.gff. Exiting.

This may be that the 'chromosome' name doesn't match in bams and gff. need to either use same gff as yenyi did (check chrom name) or make new gff with new chrom name

found ref seq in yenyi's folder and copied to mine:
$my_path/refseqs/Mtb/Mtb_h37rv.ASM19595v2.45.Chromosome.gff3

ref seq name in header on .bam files is 'AL123456.3', on gff 'Chromosome'

```{bash}
#test to see if my commands work to change ref file
sed '25q' Mtb_h37rv.ASM19595v2.45.Chromosome.gff3 | sed 's/^Chromosome/AL123456.3/g' > test.txt
```

change all labels in gff to 'AL123456.3':

```{bash}
sed 's/^Chromosome/AL123456.3/g' Mtb_h37rv.ASM19595v2.45.Chromosome.gff3 > Mtb_h37rv.ASM19595v2_AL123456.3.gff3
```

new ref seq for bedtools coverage: d/in16/u/sj003/refseqs/Mtb/Mtb_h37rv.ASM19595v2_AL123456.3.gff3

try with one file first:
```{bash}
bedtools coverage -b /d/projects/u/zchayyt/MTB_sample_accession_files/sample_accessions/PRJNA390669_12/BWA_mem/SRR5689224_sorted.bam -a /d/in16/u/sj003/refseqs/Mtb/Mtb_h37rv.ASM19595v2_AL123456.3.gff3  > SRR5689224_cds_cov.bg
```

then use edited script
```{bash}
nohup bash $my_path/scripts/iterate_bedcov_cds.sh >& run_bedcov_cds_out &
```

This seems to work. work out coverage plots for cds only.

![boxplot for coverage percentiles for cds only](Images/boxplot_PRJNA390669_cds.png)
Run baerhunter 'count_features' on all datasets with new bh gff (like Rosanna)? Or do I use R Subread 'feature counts?' like YenYi. Essentially, the same thing, with a formatted output file. Do I need to filter for expression?

write script to iterate through datasets

```{R bh_count_features1.R}

# usage: bh_count_features.R

# script to use count_features function to count reads for newly annotated ncRNA and UTRs in 
# multiple datasets

library(devtools)
#devtools::install_github("jenjane118/baerhunter", dependencies=FALSE)
# local edits
devtools::load_all("/d/in16/u/sj003/baerhunter")
library(baerhunter)
library(Rsamtools)
library(Rsubread)

## functions to get functions to re-define (from local version)
#source("/d/in16/u/sj003/baerhunter/R/feature_file_editor.R")

# create new directory for results

if (!(dir.exists("./output_BH_15_03/"))) { dir.create("./output_BH_15_03/")
}

# Read in list of datasets
directory_list <- scan("dataset_list.txt", what="", sep="\n")

for (i in 1: length(directory_list)){
  dataset_name<-sub("/d/in19/u/zchayyt/sample_accessions/", "",    directory_list[i])
  dataset_name<-sub("/BWA_mem/", "/", dataset_name)
  output_directory<-paste("/d/in16/u/sj003/output_BH_15_03/", dataset_name, sep="")
  
  print(output_directory)

# run feature_file_editor to create .gff3 file with new annotations
  count_features(bam_dir=directory_list[i],
                    annotation_dir= "/d/in16/u/sj003/",
                    annotation_file="combined_gffs_01_03.gff3",
                    output_dir=output_directory,
                    chromosome_alias_file="/d/in16/u/sj003/chromosome.txt",
                    target_features=c("gene","putative_sRNA", "putative_UTR"),
                    strandedness="reversely_stranded",
                    is_paired_end=TRUE
                    )
}



```

```{bash}
R CMD BATCH bh_count_features.R
```

Adjusted R script to just do one dataset and see if it works. (PRJNA390669_12)
```{r bh_count_features.R}
# usage: bh_count_features.R

# script to use count_features function to count reads for newly annotated ncRNA and UTRs in 
# multiple datasets

library(devtools)
#devtools::install_github("jenjane118/baerhunter", dependencies=FALSE)
# local edits
devtools::load_all("/d/in16/u/sj003/baerhunter")
library(baerhunter)
library(Rsamtools)
library(Rsubread)
# create new directory for results

if (!(dir.exists("./output_BH_16_03/"))) { dir.create("./output_BH_16_03/")
}

directory<-c("/d/in19/u/zchayyt/sample_accessions/PRJNA390669_12_RC/BWA_mem/")
output_directory<-c("./output_BH_16_03/")
count_features(bam_dir=directory,
                    annotation_dir= "/d/in16/u/sj003/",
                    annotation_file="combined_gffs_01_03.gff3",
                    output_dir=output_directory,
                    chromosome_alias_file="/d/in16/u/sj003/chromosome.txt",
                    target_features=c("gene","putative_sRNA", "putative_UTR"),
                    strandedness="reversely_stranded",
                    is_paired_end=TRUE
                    )
```


```{bash}
#!/bin/bash

# shell script to run R script
source ~/.bashrc
conda activate r_3.6
R CMD BATCH /d/in16/u/sj003/scripts/bh_count_features.R
~
```


```{bash}
chmod +x scripts/run_bh_countfeatures.sh
nohup scripts/run_bh_countfeatures.sh >& run_bh_countfeatures_r.out &
```

bh count_features function uses [Rsubread](https://bioconductor.org/packages/release/bioc/vignettes/Rsubread/inst/doc/SubreadUsersGuide.pdf)

Rsubread creates loads of temp files in directory.
Will run through all of bam files once for each target feature type: "gene","putative_sRNA", "putative_UTR"

transferred these to mac

Run again with PRJNA327080_15 (don't open bash shell first--use tcsh shell with bash script). change output file to dataset name.

copied Yen-Yi's script from github: "MSci Research Project Code.R"

the "counts.csv" files are equivalent to counts df in yen yi's code. he then binds together to make large dataframe (combinded count matrix) for all features together

Make counts matrix combining all of the counts files from each dataset.

```{r make_counts_matrix.R}
#read in each file--needs to be in order
# do I need to normalise counts with bh or normalise with VST transformation? 

#1) put together each feature type with all four datasets (in particular order as in conditions file)
# Use cbind to bind together samples with same genes/rnas
# one fewer colnames than columns

#2) put together 3 types into one matrix

# read in count files for genes

gen_a<-read.delim("~/git/mtb_modules/count_files/counts_PRJEB65014/gene_Counts.csv", header=T)
gen_b<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA327080_15/gene_Counts.csv", header=T)
gen_c<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA278760/gene_Counts.csv", header=T)
gen_d<-read.delim("~/git/mtb_modules/count_files/PRJNA390669_12/gene_Counts.csv", header=T)

countdata_CDS<-cbind(gen_a, gen_b, gen_c, gen_d)
nrow(countdata_CDS)
#4018

# create countdata file for putative srnas
rna_a<-read.delim("~/git/mtb_modules/count_files/counts_PRJEB65014/putative_sRNA_Counts.csv", header=T)
rna_b<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA327080_15/putative_sRNA_Counts.csv", header=T)
rna_c<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA278760/putative_sRNA_Counts.csv", header=T)
rna_d<-read.delim("~/git/mtb_modules/count_files/PRJNA390669_12/putative_sRNA_Counts.csv", header=T)
countdata_rna<-cbind(rna_a, rna_b, rna_c, rna_d)

#create countdata file for putative utrs
utr_a<-read.delim("~/git/mtb_modules/count_files/counts_PRJEB65014/putative_UTR_Counts.csv", header=T)
utr_b<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA327080_15/putative_UTR_Counts.csv", header=T)
utr_c<-read.delim("~/git/mtb_modules/count_files/counts_PRJNA278760/putative_UTR_Counts.csv", header=T)
utr_d<-read.delim("~/git/mtb_modules/count_files/PRJNA390669_12/putative_UTR_Counts.csv", header=T)

countdata_utr<-cbind(utr_a, utr_b, utr_c, utr_d)

#create a combined count matrix for all features 
countdata <- rbind(countdata_CDS,countdata_utr,countdata_rna)
colnames(countdata) <- gsub("\\_sorted$","",colnames(countdata))

# dataframe of sample names and which dataset it belongs to
dataset<-c(rep("PRJEB65014_3/E-MTAB-6011", 3), 
           rep("PRJNA327080/GSE83814", 15),
           rep("PRJNA278760/GSE67035", 22),
           rep("PRJNA390669/GSE100097", 12))

sample_names<-colnames(countdata)
sample_df<-data.frame(sample_names, dataset) 
write.table(sample_df, "~/git/mtb_modules/dataset_samples.txt", quote=F, row.names = F, col.names = F)
        
#inspection of matrix 
class(countdata)
head(countdata)
tail(countdata)
nrow(countdata)
length(countdata)
```


Need to make spreadsheet with samples and conditions--need to download from ncbi

![summary of replicates and conditions](~/git/mtb_modules/Images/conditions.png)
PRJEB65014_3:  ERR2103718 ERR2103722 ERR2103723

Downloaded all the metadata files for each of above datasets. ONe is from Array Express and others are from NCBI SRA RunSelector.

Check format.
```{r make_conditions_file.R}

# example from Array Express metadata
meta1<-read.delim("~/git/mtb_modules/conditions_metadata/E-MTAB-6011.sdrf.txt", sep="\t", header=T, stringsAsFactors = F)
View(meta1)
#extract columns 30 (ENA run number), 7 (genotype--make sure wild type h37rv), 8 (growth condition)
meta1_df<-data.frame(sample=c("ERR2103718", "ERR2103722", "ERR2103723"), condition=c("ammonium", "histidine", "lysine"))

meta2<-read.csv("~/git/mtb_modules/conditions_metadata/PRJNA278760.txt",
                 header=T, stringsAsFactors = F)
View(meta2)
# col 1 (run), 5 (bioproject=dataset name), 27 (growth condition)

meta2_df<-data.frame(meta2$Run, meta2$Condition)
head(meta2_df)
colnames(meta2_df)<-c("sample", "condition")

meta3<-read.csv("~/git/mtb_modules/conditions_metadata/PRJNA327080.txt",
                 header=T, stringsAsFactors = F)

View(meta3)

meta3_df<-data.frame(meta3$Run, paste(meta3$growth_condition, meta3$Timepoint, sep="_"))

head(meta3_df)
colnames(meta3_df)<-c("sample", "condition")

meta4<-read.csv("~/git/mtb_modules/conditions_metadata/PRJNA390669_12.txt", header=T, stringsAsFactors = F)
View(meta4)

meta4_df<-data.frame(meta4$Run, paste(meta4$carbon_source, meta4$growth_phase, sep="_"))
colnames(meta4_df)<-c("sample", "condition")
#combine into one csv, 'conditions.txt' for use with DESeq in bh

#make dataframe baased on columns from count matrix
sample_names<-colnames(countdata)
conditions_df<-data.frame(sample_names)
total_meta<-rbind(meta1_df, meta2_df, meta3_df, meta4_df)
nrow(total_meta)
# add conditions in same order as count matrix
for (i in 1:nrow(conditions_df)){
  conditions_df$condition[i]<-
              total_meta$condition[which(
              total_meta$sample==conditions_df$sample_names[i])]
}
nrow(conditions_df)  
View(conditions_df)
# make csv of conditions for use in DESeq
write.csv(conditions_df, "~/git/mtb_modules/mtb_conditions.txt", row.names = F, quote=F)

```

3 samples from PRJEB65014 listed as 'control' conditions in YenYi's project, but actually 3 different nitrogen sources:

ERR2103718 NH3, ERR2103722 His, ERR2103723 Lys

I have a question about the datasets in YenYi's projects. One of the datasets with 3 samples is labelled 'control'. I have had to look up and find the metadata for each dataset to use for differential expression, and the samples in the dataset actually use three different exclusive nitrogen sources (ammonia, histidine and lysine). I'm not sure any of those three are standard--I've definitely read that there is differential expression of some genes depending on ammonia concentration, for example. But maybe the ammonia is the 'control' experiment? Does it matter? the other experiments seem to have controls. Sharon clarified not a control--part of minimal media to control nitrogen source. Need to include this in conditions.


Also, conditions for PRJNA390669 include lipids/non-lipids in 3 diff growth conditions (stationary, exponential, hypoxic). Which is control group? Looks like he has used only dextrose exponential as control (2 samples).

Conditions for PRJNA327080 include 'hypoxia/persistence' and 'reaeration/reactivation'. YenYi calls all reaeration control despite 4 time points? None of these really control as all have been through extended hypoxia and reactivation, but perhaps we could use 4 days time point as control? (maybe 3 as well?)


Conditions for PRJNA278760 (GSE67035) includes two repl 'tylox pH7.0' and this is used as control. Verified with Sharon that tyloxopol is detergent and so this should be ok for control. 

I could potentially include some control samples (3) from Gerrick experiments
(PRJNA451488, H37Rv sRNAseq 7H9 rep1-3) but these are sequenced on 'NextSeq550' so may need different processing/poorer quality?


Filter for expression? use tpm normalisation in bh or normalise data (VCF) after combine?



By default, R will choose a reference level for factors based on alphabetical order. Then, if you never tell the DESeq2 functions which level you want to compare against (e.g. which level represents the control group), the comparisons will be based on the alphabetical order of the levels. There are two solutions: you can either *explicitly tell results which comparison to make using the contrast argument (this will be shown later), or you can explicitly set the factors levels*. In order to see the change of reference levels reflected in the results names, you need to either run DESeq or nbinomWaldTest/nbinomLRT after the re-leveling operation. Setting the factor levels can be done in two ways, either using factor …or using relevel, just specifying the reference level:


```{r deseq2}

library(DESeq2)
        if (!requireNamespace("BiocManager", quietly = TRUE))
          install.packages("BiocManager")

#check order is same for count data and conditions data
all(conditions_df$sample_names == colnames(countdata))
#read in table of metadata
conditions_df<-read.csv("~/git/mtb_modules/mtb_conditions.txt")

#change some of conditions to control for this study 
control.metadata<-conditions_df
control_conds<-c("high_iron", "tyloxapol_pH7.0", "reaeration_day 4", "butyrate_plus_glucose", "dextrose_exponential", "dextrose_stationary")
for (i in 1:nrow(control.metadata)){
  if (control.metadata$condition[i] %in% control_conds){
    control.metadata$condition[i]<-"control"
  }
}
#add in dataset name
dataset<-c(rep("E-MTAB-6011", 3), 
           rep("GSE83814", 15),
           rep("GSE67035", 22),
           rep("GSE100097", 12))
control.metadata$study<-dataset

View(control.metadata)
#turns character into a factor, ordered=F becuase levels not given in any order
control.metadata$condition <- factor(control.metadata$condition, ordered = FALSE)
#this step defined control samples as the base reference 
control.metadata$condition <- relevel(control.metadata$condition, "control") 
control.condition <- factor(control.metadata$condition)
# makes new conditions df with factors as conditions instead of characters, have subbed in 'control' for conditions considered as a control in this study. 
control.coldata<-data.frame(row.names=colnames(countdata), control.condition)

#construct deseq dataset
dds<-DESeqDataSetFromMatrix(countData = countdata,
                              colData = control.coldata,
                              design = ~control.condition)

# pre-filter reads to exclude rows with very low expression--makes more efficient
keep <- rowSums(counts(dds)) >= 10
dds <- dds[keep,]


#VST transformation; setting vsd parameter of blind = TRUE will result in over-estimating the dispersion and may result in overshrinking transformation, resulting in loss of gene signals 
vsd<-vst(dds,blind=FALSE)

```


```{r plot_rawdata}
# dataset name for index
View(sample_df)
dataset<-c(rep("PRJEB65014_3/E-MTAB-6011", 3), 
           rep("PRJNA327080/GSE83814", 15),
           rep("PRJNA278760/GSE67035", 22),
           rep("PRJNA390669/GSE100097", 12))
#boxplot for original data 
dds.untransformed <- assay(dds)
colnames(dds.untransformed)<-colnames(dds)
par(cex.axis=0.5) 
par(mar=c(4,2,1,1))
colors = colors = c(rep("#440154FF",3),rep("#31688EFF",15),rep("#FDE725FF",22),rep("#35B779FF",12))

plot.new()
original.boxplot <- boxplot(dds.untransformed, 
                            PchCex =0.01,
                            axes=TRUE,
                            las=2,
                            col=colors, 
                            ylim = c(0,4500),
                            outline =TRUE,
                            outcex=0.35)
#legend("topleft", 
#       legend=c("E-MTAB-6011", "GEO:GSE83814", "GEO:GSE67035", "GEO:GSE100097"),  
#       col = c("#440154FF","#31688EFF","#FDE725FF","#35B779FF"), 
#       fill= c("#440154FF","#31688EFF","#FDE725FF","#35B779FF"),
#       cex = 0.75, 
#       )
```


PCA

```{r pca}
library(ggplot2)

 #PCA plotting with DESeq2 in built function 
        PCA.prelim <- plotPCA(vsd,intgroup="control.condition")

        #generating PCA table 
        PCA.data <- data.frame(row.names=colnames(countdata),
                               condition=factor(control.metadata$condition),
                               dataset=factor(control.metadata$study))
        PCA.data.plot <- prcomp(t(dds.vsd))
        df.vst <- as.data.frame(PCA.data.plot$x)
        df.vst$group <- PCA.data$condition
        df.vst$dataset <-PCA.data$dataset
        summary(PCA.data.plot)
        
        #establishing a custom viridis colour palette
        toned_down_pal <- c("#FFBF00","#31688EFF","#35B779FF","#CA0020")

        #PCA plot for VST transformed data 
        custom <- ggplot(df.vst,aes(x=PC1,y=PC2,color=dataset,shape=group)) + scale_shape_manual(values = 0:16) + geom_point(size=3) + xlab("PC1 (42%)") + ylab("PC2 (32%)")
        custom <- custom + scale_color_manual(values = toned_down_pal) + theme_bw()
        custom
        
        
```
Shows batch effects in 2 datasets.

![Dendrogram VST transformed data, no batch correction](~/git/mtb_modules/Images/dendrogram_vst.png)


```{r batch_effect_correction}
#batch effect correction using limma; requirement to define batch effect 
        batch.table <- data.frame(study=control.metadata$study,condition=NA) 
        batch.table$condition <- control.metadata$condition 
        limma.expr<-removeBatchEffect(x=dds.vsd,
                                      batch=batch.table$study,
                                      batch2=NULL,
                                      covariates=NULL,
                                      design=model.matrix(~ batch.table$condition)) 

        #generating PCA table post-limma
        datExpAdj <- t(limma.expr)
        pca_limma <- prcomp(datExpAdj)
        df.vst.b <- as.data.frame(pca_limma$x)
        df.vst.b$group <- control.metadata$condition
        df.vst.b$dataset <- control.metadata$study
        summary(pca_limma) 

        #PCA plot for VST transformed data post-limma; PC1 PC2
        after.limma <- ggplot(df.vst.b,aes(x=PC1,y=PC2,color=dataset, shape=group)) + scale_shape_manual(values = 0:16) + geom_point(size=3) + xlab("PC1 (38%)") + ylab("PC2 (27%)")
        after.limma <- after.limma + scale_color_manual(values = toned_down_pal) + theme_bw()
        after.limma
        #PC2 PC3
        after.limma2 <- ggplot(df.vst.b,aes(x=PC2,y=PC3,color=dataset, shape=group)) + scale_shape_manual(values = 0:16) + geom_point(size=3) + xlab("PC2 (27%)") + ylab("PC3 (22%)")
        after.limma2 <- after.limma2 + scale_color_manual(values = toned_down_pal) + theme_bw()
        after.limma2
        #PC3 PC4
        after.limma3 <- ggplot(df.vst.b,aes(x=PC3,y=PC4,color=dataset, shape=group)) + scale_shape_manual(values = 0:16) + geom_point(size=3) + xlab("PC3 (22%)") + ylab("PC4 (19%)")
        after.limma3 <- after.limma3 + scale_color_manual(values = toned_down_pal) + theme_bw()
        after.limma3

```
![Dendrogram of VST transformed, post limma](~/git/mtb_modules/Images/dendro_vst_limma.png)


Still see batch effects for smallest dataset.




